# hadoop全分布式部署.md
环境说明：

系统：centos7-x 软件：hadoop2.6.0、JDK8
## 集群规划
ip地址|主机名|安装软件|进程
-|-|-|-|
192.168.188.4|master|hadoop、jdk|NameNode
192.168.188.3|slave1|hadoop、jdk|DataNode
192.168.188.5|slave2|hadoop、jdk|DataNode

> 配置免密登陆
1. 配置`/etc/hosts`文件
```
192.168.188.4 master
192.168.188.3 slave1
192.168.188.5 slave2             
```


2. 操作指令
```
ssh localhost

ssh-keygen -t rsa

cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys

```

3. 把文件`scp`到所有子节点

```
scp ~/.ssh/authorized_keys root@slave1:~/.ssh/authorized_keys
scp ~/.ssh/authorized_keys root@slave2:~/.ssh/authorized_keys
```

4. 配置文件
- slaves
- hadoop-env.sh
- yarn-env.sh
- core-site.xml
- hdfs-site.xml
- yarn-site.xml
- mapred-site.xml
---
1. slaves  
```
# 此文件内为启动DataNode节点
slave1
slave2
```


2. core-site.xml
```
<configuration>
    <property>    
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
        <description>HDFS的URI，文件系统://namenode标识:端口号</description>
    </property>
    <property>    
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop/tmp</value>
        <description>namenode上本地的hadoop临时文件夹</description>  
    </property>

</configuration>
```

3. hdfs-site.xml
```
<configuration> 
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:50090</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/name</value>
        <description>namenode上存储hdfs名字空间元数据 </description>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/data</value>
        <description>datanode上数据块的物理存储位置</description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>hadoop数据备份数</description>
    </property>
</configuration>
```
4. yarn-site.xml
```
<configuration>
    <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>Master</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:50070</value>
        <description>这个地址是mr管理界面的</description>
    </property>
</configuration>
```
5. mapred-site.xml(去除后缀.template)
```
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
        <description>mapreduce.framework.name指的是使用yarn运行mapreduce程序。</description> 
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value></value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>master:19888</value>
    </property>
</configuration>
```

## 创建文件夹
我们在配置文件中配置了一些文件夹路径，现在我们来创建他们，在`/usr/local/hadoop/`目录下操作，建立`tmp`、`/tmp/dfs/name`、`/tmp/dfs/data`目录，执行如下命令 ：
```
mkdir /usr/local/hadoop/tmp 
mkdir /usr/local/hadoop/tmp/dfs/data 
mkdir /usr/local/hadoop/tmp/dfs/name
```

> 下面的指令均在namenode节点使用就行
## 格式化
在使用Hadoop之前我们需要格式化一些hadoop的基本信息。 使用如下命令：  
```
hadoop namenode -format
```
## 接着开启 NameNode 和 DataNode 守护进程。
```
/usr/local/hadoop/sbin/start-dfs.sh  #start-dfs.sh 是个完整的可执行文件，中间没有空格
```

成功启动后，可以访问 Web 界面 http://localhost:50070 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。
![](http://dblab.xmu.edu.cn/blog/wp-content/uploads/2014/08/install-hadoop-17-web-ui.png)