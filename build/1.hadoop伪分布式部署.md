# HADOOP 伪分布式部署
环境说明：

系统：centos7-x 软件：hadoop2.6.0、JDK8

> 前提：配置免密登陆,关闭防火墙
```
#查看防火墙状态
firewall-cmd --state

#停止firewall
systemctl stop firewalld.service

#禁止firewall开机启动
systemctl disable firewalld.service 
```
1. 操作指令
```
ssh localhost

ssh-keygen -t rsa

cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys

```

## 成功截图
![](http://tmp.mada8.com/201906142256_119.png)

---

# 集群规划
ip地址|主机名|安装软件|进程
-|-|-|-|
192.168.188.4|master|hadoop、jdk8|NameNode、 DataNode、SecondaryNameNode


一、解压hadoop文件
> 记住解压、压缩gz 文件命令
```
tar -zxf /mnt/dsj/hadoop-xxx.tar.gz -C /usr/local/

mv /usr/local/hadoop-xxx /usr/local/hadoop

```

在`~/.bashrc`配置环境变量：实现仅为`当前用户`设置环境变量
```
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
最后使修改生效：source ~/.bashrc
## 成功截图

二、修改hadoop配置文件  

Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。

Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。

- core-site.xml
- hdfs-site.xml



1. core-site.xml
```
<configuration>
    <property>    
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
        <description>HDFS的URI，文件系统://namenode标识:端口号</description>
    </property>
    <property>    
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop/tmp</value>
        <description>namenode上本地的hadoop临时文件夹</description>  
    </property>

</configuration>
```

2. hdfs-site.xml
```
<configuration> 
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/name</value>
        <description>namenode上存储hdfs名字空间元数据 </description>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/data</value>
        <description>datanode上数据块的物理存储位置</description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>hadoop数据备份数</description>
    </property>
</configuration>
```

## 创建文件夹
我们在配置文件中配置了一些文件夹路径，现在我们来创建他们，在`/usr/local/hadoop/`目录下操作，建立`tmp`、`/tmp/dfs/name`、`/tmp/dfs/data`目录，执行如下命令 ：
```
mkdir /usr/local/hadoop/tmp 
mkdir /usr/local/hadoop/tmp/dfs/data 
mkdir /usr/local/hadoop/tmp/dfs/name
```
# 验证

现在配置工作已经基本搞定，接下来只需要完成：  
1.格式化HDFS文件、2.启动hadoop、3.验证Hadoop 即可

## 格式化
在使用Hadoop之前我们需要格式化一些hadoop的基本信息。 使用如下命令：  
```
hadoop namenode -format
```
### 成功截图
![](https://upload-images.jianshu.io/upload_images/7013389-959f6b44020ffa98.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  

启动Hadoop
接下来我们启动Hadoop：
```
start-dfs.sh
```

之后如果你是图形化界面，可以在你虚拟机的图形化界面中打开火狐浏览器输入：http://localhost:50070/ 或者在windows机器上输入http://虚拟机ip地址:50070/ 也可以访问 hadoop的管理页面

> 例图设置的为9870端口  

![](https://upload-images.jianshu.io/upload_images/7013389-a79fc86b86825305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)