# HADOOP 伪分布式部署
环境说明：

系统：centos7-x 软件：hadoop2.6.0、JDK8

> 前提：配置免密登陆
1. 操作指令
```
ssh localhost

ssh-keygen -t rsa

cat ~/.ssh/id_rsa.pub > ~/.ssh/authorized_keys

```

## 成功截图
![](http://tmp.mada8.com/201906142256_119.png)

---

# 集群规划
ip地址|主机名|安装软件|进程
-|-|-|-|
192.168.188.4|master|hadoop、jdk8|NameNode、 DataNode、SecondaryNameNode


一、解压hadoop文件
> 记住解压、压缩gz 文件命令
```
tar -zxf /mnt/dsj/hadoop-xxx.tar.gz -C /usr/local/

mv /usr/local/hadoop-xxx /usr/local/hadoop

```

在`~/.bashrc`配置环境变量：实现仅为`当前用户`设置环境变量
```
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
最后使修改生效：source ~/.bashrc
## 成功截图

二、修改hadoop配置文件  
- hadoop-env.sh
- yarn-env.sh
- core-site.xml
- hdfs-site.xml
- yarn-site.xml
- mapred-site.xml

1. hadoop-env.sh 配置  

两个env.sh文件主要是配置JDK的位置  
[怎么配置jdk？](0.jdk安装+环境变量配置(所有组件通用).md)  
提示：如果忘记了JDK的位置了，输入 echo $JAVA_HOME就可以看到哦。  
编辑`hadoop-env.sh`,`yarn-env.sh`分别插入以下代码
```
export JAVA_HOME=/usr/local/java
```


2. core-site.xml
```
<configuration>
    <property>    
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
        <description>HDFS的URI，文件系统://namenode标识:端口号</description>
    </property>
    <property>    
        <name>hadoop.tmp.dir</name>
        <value>/usr/local/hadoop/tmp</value>
        <description>namenode上本地的hadoop临时文件夹</description>  
    </property>

</configuration>
```

3. hdfs-site.xml
```
<configuration> 
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/name</value>
        <description>namenode上存储hdfs名字空间元数据 </description>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/tmp/dfs/data</value>
        <description>datanode上数据块的物理存储位置</description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
        <description>hadoop数据备份数</description>
    </property>
</configuration>
```
4. yarn-site.xml
```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:50070</value>
        <description>这个地址是mr管理界面的</description>
    </property>
</configuration>
```
5. mapred-site.xml(去除后缀.template)
```
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
        <description>mapreduce.framework.name指的是使用yarn运行mapreduce程序。</description> 
    </property>
</configuration>
```
## 创建文件夹
我们在配置文件中配置了一些文件夹路径，现在我们来创建他们，在`/usr/local/hadoop/`目录下操作，建立`tmp`、`/tmp/dfs/name`、`/tmp/dfs/data`目录，执行如下命令 ：
```
mkdir /usr/local/hadoop/tmp 
mkdir /usr/local/hadoop/tmp/dfs/data 
mkdir /usr/local/hadoop/tmp/dfs/name
```
# 验证

现在配置工作已经基本搞定，接下来只需要完成：  
1.格式化HDFS文件、2.启动hadoop、3.验证Hadoop 即可

## 格式化
在使用Hadoop之前我们需要格式化一些hadoop的基本信息。 使用如下命令：  
```
hadoop namenode -format
```
### 成功截图
![](https://upload-images.jianshu.io/upload_images/7013389-959f6b44020ffa98.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)  

启动Hadoop
接下来我们启动Hadoop：
```
start-dfs.sh
```

之后如果你是图形化界面，可以在你虚拟机的图形化界面中打开火狐浏览器输入：http://localhost:50070/ 或者在windows机器上输入http://虚拟机ip地址:50070/ 也可以访问 hadoop的管理页面

> 例图设置的为9870端口  

![](https://upload-images.jianshu.io/upload_images/7013389-a79fc86b86825305.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)